#Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import OneHotEncoder, StandardScaler,LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score

#Load the data
car_data = pd.read_csv("C:\\Users\\Dell\\Documents\\shobi\\car data.csv")

# Display basic information and check for missing values
print(car_data.info())
car_data

# Define features and target variable
X = car_data.drop('Selling_Price', axis=1)  # Assuming 'price' is the column with car prices
y = car_data['Selling_Price']

#Define categorical and numerical features
categorical_features = ['Car_Name', 'Fuel_Type', 'Selling_type', 'Transmission']
numerical_features = ['Year', 'Present_Price','Driven_kms', 'Owner']

#Preprocessing Scaling numerical features and one-hot encoding categorical features
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ])

#Define the model pipeline
model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', RandomForestRegressor())
])

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Define the parameter grid for GridSearchCV
param_grid = {'regressor__n_estimators':[50, 100, 200],
              'regressor__max_depth':[None, 10, 20, 30],
              'regressor__min_samples_split':[2, 5, 10]}

#Perform GridSearchCV to find the best hyperparameters
grid_search = GridSearchCV(model, param_grid, cv=5, scoring='r2', n_jobs=-1)
grid_search.fit(X_train,y_train)

#Print the best parameters and best score
print("Best parameters found:", grid_search.best_params_)
print("Best R2 score:", grid_search.best_score_)

#Evaluate the model on the test set
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)

#Calculate and print performance matrics
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print("Mean Absolute Error:", mae)
print("R2 Score:", r2)

#Function to predict car price
def train_and_predict_car_price(input_features):
    # Load the dataset
    # Path to your file
    car_data = pd.read_csv("C:\\Users\\Dell\\Documents\\shobi\\car data.csv")

    # Handle missing values if any (for simplicity, let's drop them)
    car_data = car_data.dropna()

    # Encode categorical variables
    label_encoders = {}
    for column in car_data.select_dtypes(include=['object']).columns:
        le = LabelEncoder()
        car_data[column] = le.fit_transform(car_data[column])
        label_encoders[column] = le

    # Define features and target variable
    X = car_data.drop('Selling_Price', axis=1)  # Assuming 'Selling_Price' is the column with car prices
    y = car_data['Selling_Price']

    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Feature scaling
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    # Initialize and train the model (Random Forest Regressor)
    model = RandomForestRegressor()
    model.fit(X_train, y_train)

    # Prepare the input data (make sure input_features is a list with the same order as X)
    input_features_scaled = scaler.transform([input_features])

    # Predict the price
    predicted_price = model.predict(input_features_scaled)[0]

    return predicted_price
# Example usage:
# Assuming input_features = [Year, Present_Price, Kms_Driven, Fuel_Type, Seller_Type, Transmission, Owner]
input_features = [2014, 5.59, 27000, 0, 0, 0, 0, 0]  # Example values based on dataset features
predicted_price = train_and_predict_car_price(input_features)
print(f"Predicted Car Price: {predicted_price}")